{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rafael/anaconda3/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#constants\n",
    "image_size=(200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images to memory\n",
    "dataset_dir = '/home/rafael/datasets/PetImages/'\n",
    "\n",
    "class LoadDataset():\n",
    "    def __init__(self, path_to_dataset, image_size=(200, 200), convert_to_gray=False, shuffle=True, limit=0):\n",
    "        \n",
    "        self.data = []\n",
    "        self.classes = []\n",
    "        self.path_to_dataset = path_to_dataset\n",
    "        self.image_size = image_size\n",
    "        self.convert_to_gray = convert_to_gray\n",
    "        self.shuffle = shuffle\n",
    "        self.limit = limit\n",
    "        \n",
    "        self.channels = 3\n",
    "        if self.convert_to_gray:\n",
    "            self.channels = 1\n",
    "        \n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        #At first, find the folders containing the images\n",
    "        for class_name in os.listdir(self.path_to_dataset):\n",
    "                \n",
    "            #Add a new class\n",
    "            self.classes.append(class_name)\n",
    "            \n",
    "            #Then, look for the class names\n",
    "            path_to_images = os.path.join(self.path_to_dataset, class_name)\n",
    "            \n",
    "            print(self.limit)\n",
    "            \n",
    "            for i, image_name in enumerate(os.listdir(path_to_images)):\n",
    "                \n",
    "                if (self.limit != 0) and (i > self.limit):\n",
    "                    print(\"Reached limit\")\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    #Load each image to memory\n",
    "                    image = cv2.imread(os.path.join(path_to_images, image_name))\n",
    "                    \n",
    "                    #Check if image was loaded. If not, discard entry\n",
    "                    if image is None:\n",
    "                        continue\n",
    "                        \n",
    "                    #Resize image\n",
    "                    image = cv2.resize(image, self.image_size)\n",
    "                    \n",
    "                    \n",
    "                    if self.convert_to_gray:\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                        \n",
    "                    #Load new image into dataset\n",
    "                    self.data.append([image, class_name])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "        \n",
    "        \n",
    "        self.separate_data_into_x_y()\n",
    "                \n",
    "    def shuffle_data(self):\n",
    "        random.shuffle(self.data)\n",
    "        \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def separate_data_into_x_y(self):\n",
    "        for entry, label in self.data:\n",
    "            self.X.append(entry)\n",
    "            self.Y.append(label)\n",
    "            \n",
    "            \n",
    "        self.X = np.array(self.X).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\n",
    "        self.X = self.X / 255\n",
    "            \n",
    "    def get_training_set(self, training=0.7, test=0.3):\n",
    "        \n",
    "        X_training = []\n",
    "        Y_training = []\n",
    "        X_test = []\n",
    "        Y_test = []\n",
    "        \n",
    "        \n",
    "        size_of_training = round(training * self.get_dataset_size())\n",
    "        size_of_test = round(test * self.get_dataset_size())\n",
    "        \n",
    "        print('=== Dataset will be separated as follows === ')\n",
    "        print('Training: ', training, ' - # of elements: ', size_of_training)\n",
    "        print('Test: ', test, ' - # of elements: ', size_of_test)\n",
    "        \n",
    "        #Training\n",
    "        for i in range(0, size_of_training):\n",
    "            X_training.append(self.X[i])\n",
    "            Y_training.append(self.Y[i])\n",
    "            \n",
    "        #Test\n",
    "        for i in range(0, size_of_test):\n",
    "            X_test.append(self.X[i])\n",
    "            Y_test.append(self.Y[i])\n",
    "            \n",
    "        X_training = np.array(X_training).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\n",
    "        Y_training = to_categorical(Y_training)\n",
    "        #Y_training = np.array(Y_training).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\n",
    "        X_test = np.array(X_test).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\n",
    "        Y_test = to_categorical(Y_test)\n",
    "        #Y_test = np.array(Y_test).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\n",
    "            \n",
    "        return (X_training, Y_training), (X_test, Y_test)            \n",
    "        \n",
    "        \n",
    "    \n",
    "dataset = LoadDataset(dataset_dir, convert_to_gray=True, limit=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "1000\n",
      "Reached limit\n",
      "1000\n",
      "Reached limit\n",
      "1991\n",
      "[[array([[ 61,  68,  83, ...,  50,  59,  70],\n",
      "       [ 87,  87,  87, ...,  69,  73,  78],\n",
      "       [ 48,  48,  57, ...,  76,  73,  74],\n",
      "       ...,\n",
      "       [ 81,  90,  82, ...,  80, 135, 104],\n",
      "       [ 91,  77,  72, ...,  79, 129,  87],\n",
      "       [ 65,  57,  56, ...,  81, 127,  83]], dtype=uint8), 'Dog'], [array([[154, 146, 137, ...,  22,  18,  18],\n",
      "       [153, 145, 135, ...,  22,  19,  19],\n",
      "       [150, 142, 133, ...,  21,  22,  22],\n",
      "       ...,\n",
      "       [ 86,  85,  82, ...,  31,  27,  30],\n",
      "       [ 84,  81,  78, ...,  30,  27,  24],\n",
      "       [ 81,  78,  78, ...,  30,  32,  30]], dtype=uint8), 'Cat'], [array([[115, 118, 120, ..., 104, 107, 112],\n",
      "       [122, 124, 123, ..., 103, 106, 110],\n",
      "       [117, 122, 125, ..., 112, 110, 109],\n",
      "       ...,\n",
      "       [ 91,  84,  94, ...,  90,  37,  61],\n",
      "       [ 73,  76,  69, ...,  79,  90,  51],\n",
      "       [ 72,  80,  34, ...,  71,  70,  86]], dtype=uint8), 'Dog'], [array([[191, 183, 185, ...,  90,  46,  34],\n",
      "       [181, 191, 169, ...,  67,  31,  83],\n",
      "       [184, 171, 177, ...,  41,  46,  88],\n",
      "       ...,\n",
      "       [106, 101, 101, ..., 178, 185, 183],\n",
      "       [100, 105,  95, ..., 186, 180, 180],\n",
      "       [105, 107,  89, ..., 167, 179, 181]], dtype=uint8), 'Dog'], [array([[ 97, 100, 104, ...,  93,  94,  95],\n",
      "       [ 93,  95,  99, ...,  93,  94,  95],\n",
      "       [ 88,  89,  94, ...,  93,  94,  95],\n",
      "       ...,\n",
      "       [ 25,  25,  25, ...,  80,  80,  80],\n",
      "       [ 25,  25,  25, ...,  79,  81,  82],\n",
      "       [ 25,  25,  25, ...,  78,  80,  82]], dtype=uint8), 'Cat']]\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.data))\n",
    "dataset.shuffle_data()\n",
    "print(dataset.data[:5])\n",
    "\n",
    "dataset.load_data()\n",
    "\n",
    "print(len(dataset.data))\n",
    "dataset.shuffle_data()\n",
    "print(dataset.data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = dataset.data[1001]\n",
    "img, name = p\n",
    "print(name)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset will be separated as follows === \n",
      "Training:  0.7  - # of elements:  1394\n",
      "Test:  0.3  - # of elements:  597\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Dog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62047d769f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7f776603ea28>\u001b[0m in \u001b[0;36mget_training_set\u001b[0;34m(self, training, test)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mX_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mY_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m#Y_training = np.array(Y_training).reshape(-1, self.image_size[0], self.image_size[1], self.channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Dog'"
     ]
    }
   ],
   "source": [
    "(X_training, Y_training), (X_test, Y_test)  = dataset.get_training_set()\n",
    "print(X_training.shape)\n",
    "\n",
    "x = dataset.X\n",
    "x.shape\n",
    "Y_training.shape\n",
    "\n",
    "#X_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # The third convolution\n",
    "    #tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_training, Y_training, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
